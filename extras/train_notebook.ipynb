{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yp/jdzdnmvx69n8p5szmm_1rbhc0000gp/T/ipykernel_81001/2957602081.py:5: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "from dataset import Data\n",
    "from tqdm import tqdm\n",
    "from torcheval.metrics.functional import peak_signal_noise_ratio\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TrainConfigs:\n",
    "    learning_rate: float = 1e-4\n",
    "    epochs: int = 10\n",
    "    batch_size: int = 1\n",
    "    save_every: int = 2\n",
    "    crop_size: int = (300,300)\n",
    "    \n",
    "    save_path: str = 'train_files'\n",
    "    images_path: str = 'images'\n",
    "    train_csv_path: str = 'train.csv'\n",
    "    test_csv_path: str = 'test.csv'\n",
    "    \n",
    "    optimizer: torch.optim = torch.optim.Adam\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        self.train_df = pd.read_csv(self.train_csv_path)\n",
    "        self.test_df = pd.read_csv(self.test_csv_path)\n",
    "        \n",
    "        \n",
    "class Trainer(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 configs: TrainConfigs,\n",
    "                 model: models.BaseSRCNN,\n",
    "                 optim: torch.optim):\n",
    "        \"\"\"Trainer object.\n",
    "\n",
    "        Args:\n",
    "            configs (TrainConfigs): configurations of training.\n",
    "            model (models.BaseSRCNN): model to trained.\n",
    "            optim (torch.optim): uninitiated optimizer object.\n",
    "        \"\"\"\n",
    "        self.configs = configs\n",
    "        self.model = model\n",
    "        \n",
    "        # Create train and test dataset objects.\n",
    "        self.train_dataset = Data(self.configs.images_path,\n",
    "                                  self.configs.train_df,\n",
    "                                  1/self.model.args.upscale_factor,\n",
    "                                  self.configs.crop_size)\n",
    "        self.test_dataset = Data(self.configs.images_path,\n",
    "                                 self.configs.test_df,\n",
    "                                 1/self.model.args.upscale_factor,\n",
    "                                 self.configs.crop_size)\n",
    "        \n",
    "        # Dataloaders\n",
    "        self.train_loader = DataLoader(self.train_dataset,\n",
    "                                       self.configs.batch_size,\n",
    "                                       shuffle=True)\n",
    "        self.test_loader = DataLoader(self.test_dataset,\n",
    "                                      self.configs.batch_size,\n",
    "                                      shuffle=False)\n",
    "        \n",
    "        # Create optimizer object.\n",
    "        self.optim = optim(self.model.parameters(),lr = self.configs.learning_rate)\n",
    "        \n",
    "        # Create history for plotting later.\n",
    "        self.train_history = []\n",
    "        self.test_history = []\n",
    "        self.psnr_train = []\n",
    "        self.psnr_test = []\n",
    "        \n",
    "        # Epoch tracker\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"Train function for our model.\n",
    "        \"\"\"\n",
    "        for epoch in range(self.configs.epochs):\n",
    "            loop = tqdm(enumerate(self.train_loader))\n",
    "            \n",
    "            # Train\n",
    "            train_loss = 0.0\n",
    "            train_psnr = 0.0\n",
    "            for i, (image,image_downscaled) in loop:\n",
    "                loss,upscaled_image = self.model.train_step(image_downscaled,image)\n",
    "                self.model.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "                # Calculate psnr\n",
    "                psnr = peak_signal_noise_ratio(image,upscaled_image,1.0)\n",
    "                # Postfix for tqdm object.\n",
    "                loop.set_postfix(loss=loss.cpu().item(),psnr=psnr.cpu().item())\n",
    "                \n",
    "                # Scaling loss and psnr with batch size to calculate accurate loss later.\n",
    "                train_loss += loss.cpu().item()*image.shape[0]\n",
    "                train_psnr += psnr.cpu().item()*image.shape[0]\n",
    "            # Normalize by total number of images.\n",
    "            train_loss = train_loss/len(self.train_dataset)\n",
    "            train_psnr = train_psnr/len(self.train_dataset)\n",
    "\n",
    "            # Append loss and psnr\n",
    "            self.train_history.append(train_loss)\n",
    "            self.psnr_train.append(train_psnr)\n",
    "            \n",
    "            # Test\n",
    "            test_loss = 0.0\n",
    "            test_psnr = 0.0\n",
    "            with torch.no_grad():\n",
    "                for i,(image,image_downscaled) in enumerate(self.test_loader):\n",
    "                    loss,upscaled_image = self.model.train_step(image_downscaled,image)\n",
    "                    # Update loss and psnr\n",
    "                    test_loss += loss.cpu().item()*image.shape[0]\n",
    "                    test_psnr += peak_signal_noise_ratio(image,upscaled_image,1.0).cpu().item()*image.shape[0]\n",
    "            # Normalize\n",
    "            test_loss = test_loss/len(self.test_dataset)\n",
    "            test_psnr = test_psnr/len(self.test_dataset)\n",
    "            \n",
    "            # Append loss and psnr\n",
    "            self.test_history.append(test_loss)\n",
    "            self.psnr_test.append(test_psnr)\n",
    "            \n",
    "            # Checkpointing\n",
    "            if self.epoch%self.configs.save_every == 0:\n",
    "                self.save()\n",
    "                \n",
    "            # Update epoch number\n",
    "            self.epoch += 1\n",
    "            \n",
    "                \n",
    "    def save(self):\n",
    "        # Create directory.\n",
    "        if not os.path.exists(self.configs.save_path):\n",
    "            os.mkdir(self.configs.save_path)\n",
    "        \n",
    "        # Separate directories for different epoch path\n",
    "        dir = os.path.join(self.configs.save_path,f'epoch_{self.epoch}')\n",
    "        if not os.path.exists(dir):\n",
    "            os.mkdir(dir)\n",
    "            # Save the model first.\n",
    "            self.model.save(os.path.join(dir,f'model.pt'),\n",
    "                            self.optim)\n",
    "            torch.save({\n",
    "                'configs': self.configs,\n",
    "                'history': [self.train_history,\n",
    "                            self.test_history,\n",
    "                            self.psnr_train,\n",
    "                            self.psnr_test]\n",
    "                },os.path.join(dir,'trainer.pkl'))\n",
    "        else:\n",
    "            print(\"This version already exists.\")\n",
    "    \n",
    "    @classmethod\n",
    "    def load(cls, path: str, epoch: int,type):\n",
    "        \"\"\"Loads trainer with the model.\n",
    "\n",
    "        Args:\n",
    "            path (str): path to directory.\n",
    "            type (any): type of srcnn used. (uninitiated object)\n",
    "        \"\"\"\n",
    "        checkpoint_path = os.path.join(path,f'epoch_{epoch}')\n",
    "        model,optim = type.load(os.path.join(checkpoint_path,f'model.pt'))\n",
    "        load_dict = torch.load(os.path.join(checkpoint_path,f'trainer.pkl'))\n",
    "        configs = load_dict['configs']\n",
    "        \n",
    "        # Nested history list.\n",
    "        his = load_dict['history']\n",
    "        \n",
    "        # Create new class instance.\n",
    "        self = cls(configs,model,torch.optim.Adam)  # Dummy optimizer.\n",
    "        \n",
    "        # Put in real optimizer\n",
    "        self.optim = optim\n",
    "        \n",
    "        # Extract loss and metric histories.\n",
    "        self.train_history = his[0]\n",
    "        self.test_history = his[1]\n",
    "        self.psnr_train = his[2]\n",
    "        self.psnr_test = his[3]\n",
    "        \n",
    "        return self\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = models.ModelArgs(loss='perceptual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.SRCNN(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (3): ReLU(inplace=True)\n",
       "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (6): ReLU(inplace=True)\n",
       "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (8): ReLU(inplace=True)\n",
       "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (11): ReLU(inplace=True)\n",
       "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (13): ReLU(inplace=True)\n",
       "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (15): ReLU(inplace=True)\n",
       "  (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (25): ReLU(inplace=True)\n",
       "  (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (27): ReLU(inplace=True)\n",
       "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (29): ReLU(inplace=True)\n",
       "  (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(3,8,15,29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = TrainConfigs()\n",
    "trainer = Trainer(configs,model,torch.optim.Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:25,  1.71s/it, loss=46.2, psnr=5.95]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "Cell \u001b[0;32mIn[8], line 90\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m loss,upscaled_image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain_step(image_downscaled,image)\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 90\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     92\u001b[0m \u001b[39m# Calculate psnr\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_2 = Trainer.load('train_files',0,models.SRCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [00:17,  1.07it/s, loss=2.74, psnr=14.1]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer_2\u001b[39m.\u001b[39;49mtrain()\n",
      "Cell \u001b[0;32mIn[1], line 90\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m loss,upscaled_image \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain_step(image_downscaled,image)\n\u001b[1;32m     89\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 90\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     91\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     92\u001b[0m \u001b[39m# Calculate psnr\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    523\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    524\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/pytorch/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m     tensors,\n\u001b[1;32m    268\u001b[0m     grad_tensors_,\n\u001b[1;32m    269\u001b[0m     retain_graph,\n\u001b[1;32m    270\u001b[0m     create_graph,\n\u001b[1;32m    271\u001b[0m     inputs,\n\u001b[1;32m    272\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    273\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    274\u001b[0m )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer_2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer_2.train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mloss\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
